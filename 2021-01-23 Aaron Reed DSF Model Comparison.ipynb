{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the previous section, I had already made a OLS model. no reason to reinvent the wheel\n",
    "info_df = pd.read_csv('D:\\DSF\\houseprices_model.csv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions were already made for tuning and testing regressions\n",
    "#we'll define a function here that will allow us to test quickly\n",
    "#below to tune to the best parameters and test after\n",
    "def lrm_test():\n",
    "    y = info_df['saleprice']\n",
    "    X = info_df.drop(['saleprice'], axis=1)\n",
    "    X = sm.add_constant(X)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    y_test_predictions = lr.predict(X)\n",
    "    print('OLS Regression')\n",
    "    print(\"R-squared: {:0.2f}\".format(lr.score(X, y)))\n",
    "    print(\"\\nMean absolute error of the prediction is: {}\".format(mean_absolute_error(y, y_test_predictions)))\n",
    "    print(\"Mean squared error of the prediction is: {:3e}\".format(mse(y, y_test_predictions)))\n",
    "    print(\"Root mean squared error of the prediction is: {}\".format(rmse(y, y_test_predictions)))\n",
    "    print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y - y_test_predictions) / y)) * 100))\n",
    "    \n",
    "def knn_test(neighbors, weight):\n",
    "    y = info_df['saleprice']\n",
    "    X = info_df.drop(['saleprice'], axis=1)\n",
    "    X = sm.add_constant(X)\n",
    "    knn = KNeighborsRegressor(n_neighbors=neighbors, weights=weight)\n",
    "    knn.fit(X, y)\n",
    "    y_test_predictions = knn.predict(X)\n",
    "    score = cross_val_score(knn, X, y, cv=10)\n",
    "    print('K-Nearest Neighbors Regression')\n",
    "    print('{} neighbors and {} weighted'.format(neighbors, weight))\n",
    "    print(\"R-squared: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "    print(\"\\nMean absolute error of the prediction is: {}\".format(mean_absolute_error(y, y_test_predictions)))\n",
    "    print(\"Mean squared error of the prediction is: {:3e}\".format(mse(y, y_test_predictions)))\n",
    "    print(\"Root mean squared error of the prediction is: {}\".format(rmse(y, y_test_predictions)))\n",
    "    print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y - y_test_predictions) / y)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression\n",
      "R-squared: 0.90\n",
      "\n",
      "Mean absolute error of the prediction is: 15683.151557663708\n",
      "Mean squared error of the prediction is: 6.294095e+08\n",
      "Root mean squared error of the prediction is: 25088.035958488646\n",
      "Mean absolute percentage error of the prediction is: 9.233630379305428\n"
     ]
    }
   ],
   "source": [
    "#calling the function for the OLS Regression\n",
    "lrm_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regression\n",
      "10 neighbors and None weighted\n",
      "R-squared: 0.65 (+/- 0.10)\n",
      "\n",
      "Mean absolute error of the prediction is: 26739.378972602743\n",
      "Mean squared error of the prediction is: 1.742842e+09\n",
      "Root mean squared error of the prediction is: 41747.3625447189\n",
      "Mean absolute percentage error of the prediction is: 15.57862197347441\n"
     ]
    }
   ],
   "source": [
    "#running some knn tests with differing numbers of neighbors and weighted differently\n",
    "knn_test(10, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regression\n",
      "5 neighbors and None weighted\n",
      "R-squared: 0.66 (+/- 0.11)\n",
      "\n",
      "Mean absolute error of the prediction is: 24217.634794520545\n",
      "Mean squared error of the prediction is: 1.375583e+09\n",
      "Root mean squared error of the prediction is: 37088.85362082171\n",
      "Mean absolute percentage error of the prediction is: 14.096565530268576\n"
     ]
    }
   ],
   "source": [
    "knn_test(5, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regression\n",
      "10 neighbors and distance weighted\n",
      "R-squared: 0.66 (+/- 0.11)\n",
      "\n",
      "Mean absolute error of the prediction is: 13.561643835616438\n",
      "Mean squared error of the prediction is: 4.833562e+04\n",
      "Root mean squared error of the prediction is: 219.8536250289182\n",
      "Mean absolute percentage error of the prediction is: 0.009693321337547389\n"
     ]
    }
   ],
   "source": [
    "knn_test(10, \"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regression\n",
      "5 neighbors and distance weighted\n",
      "R-squared: 0.66 (+/- 0.11)\n",
      "\n",
      "Mean absolute error of the prediction is: 13.561643835616438\n",
      "Mean squared error of the prediction is: 4.833562e+04\n",
      "Root mean squared error of the prediction is: 219.8536250289182\n",
      "Mean absolute percentage error of the prediction is: 0.009693321337547389\n"
     ]
    }
   ],
   "source": [
    "knn_test(5, 'distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the R-squared and secondary test values, I would use the 5 neighbor with no weights model over the rest of the KNNs but would use the OLS model over any of the tested KNNs. While the distance weighted models have significantly smaller values for all of the secondary tests, the fact that they are so low lead me to believe that the model is drastically overfitting. I tried running a split using test and train but it didn't work.\n",
    "\n",
    "The data has more columns with dummy values than with distinct values. As an example, 'on paved road' has only two values (0 or 1) that relate to values ranging from 34,900 to 755,000 in 'saleprice', so it can be difficult to find proper neighbors, especialy when compared to OLS being able to apply each variable as a coefficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
